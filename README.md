# Sustainable Machine Learning Reading Group
Reading group for Sustainable Machine Learning. We discuss papers every other week, usually on Wednesdays at 3.30PM CET. If interested reach out to Dustin or Raghav. 

---
## Upcoming meetings

### Meeting 12: 11/10/2023
* [Dustin Wright](http://dustinbwright.com/) will be presenting.

### Meeting-13: 25/10/2023
* [Pedram Bakhtiarifard](https://scholar.google.com/citations?user=wnOiOHoAAAAJ&hl=en&oi=ao) will be presenting. 

### Meeting 14: 08/11/2023
* [Daniel Geißler](https://www.linkedin.com/in/daniel-gei%C3%9Fler-68a5bb201/?originalSubdomain=de) will be presenting.

---- 
## Past meetings

### Meeting-11: 27/09/2023
* [Raghavendra Selvan](https://raghavian.github.io/) presented _Pruning vs Quantization: Which is Better?_ (Kuzmin et al. 2023). 
* [Paper](https://arxiv.org/abs/2307.02973)

### Meeting-10: 21/06/2023
* [Tong Chen](https://scholar.google.com/citations?user=KArfuYIAAAAJ&hl=fr&oi=sra) presented _Sparse Polynomial Optimization and Its Application to Deep Neural Network_. 
* [Paper](https://proceedings.neurips.cc/paper/2020/hash/dea9ddb25cbf2352cf4dec30222a02a5-Abstract.html)

### Meeting-9: 07/06/2023
* [Pedram Bakhtiarifard](https://scholar.google.com/citations?user=wnOiOHoAAAAJ&hl=en&oi=ao) presented _Once-for-All: Train One Network and Specialize it for Efficient Deployment_ (Cai et al. 2020)
* [Paper](https://arxiv.org/abs/1908.09791)


### Meeting-8: 24/05/2023
* [Eya Ben Chaaben](https://www.lisn.upsaclay.fr/members/ben-chaaben-eya/) presented _EnergyVis: Interactively tracking and exploring energy consumption for ML models_ (Shaikh et al. 2021)
* [Paper](https://dl.acm.org/doi/abs/10.1145/3411763.3451780)


### Meeting-7: 10/05/2023
* [Daniel Geißler](https://www.linkedin.com/in/daniel-gei%C3%9Fler-68a5bb201/?originalSubdomain=de) presented _Dodging the Sparse Double Descent (Quétu and Tartaglione 2023)_
* [Paper](https://arxiv.org/pdf/2303.01213.pdf)

### Meeting-6: 26/04/2023
* [Sebastian Hammer Eliassen](https://github.com/sebeliassen/) will present _EXACT: Scalable Graph Neural Networks Training via Extreme Activation Compression (Liu et al. 2022)_
* [Paper](https://openreview.net/forum?id=vkaMaq95_rX)

### Meeting-5: 12/04/2023
* [Emil Jørgensen Njor](https://scholar.google.com/citations?user=1MM7E9QAAAAJ&hl=en&oi=ao) presented _Data Aware Neural Architecture Search (Njor et al. 2023)_
* [Paper](https://www2.compute.dtu.dk/~xefa/files/conf/2023-tinyml-datanas.pdf)


### Meeting-4: 29/03/2023
* [Julian Schön](https://scholar.google.com/citations?hl=en&user=YqdxR9UAAAAJ) presented _Learning from Randomly Initialized Neural Network Features (Amid et al. 2022)_
* [Paper](https://arxiv.org/abs/2202.06438)


### Meeting-3: 16/03/2023

* [Bo Zhou](https://scholar.google.com/citations?hl=en&user=PCvtW3gAAAAJ) presented _Overcoming Oscillations in Quantization-Aware Training (Nagel et al. 2022)_ 
* [Paper](https://proceedings.mlr.press/v162/nagel22a.html)

### Meeting-2: 01/03/2023

* [Raghavendra Selvan](https://raghavian.github.io/) presented _8-bit Optimizers via Block-wise Quantization (Dettmers et al. 2022)_ 
* [Paper](https://arxiv.org/abs/2110.02861)

### Meeting-1: 15/02/2023

* [Dustin Wright](http://dustinbwright.com/) presented _An Information-Theoretic Justification for Model Pruning (Isik et al, 2022)_
* [Paper](https://arxiv.org/abs/2102.08329)

